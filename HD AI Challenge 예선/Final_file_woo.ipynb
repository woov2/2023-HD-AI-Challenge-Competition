{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2939a37",
   "metadata": {},
   "source": [
    "# Environment\n",
    "- GPU : NVIDIA GeForce GTX 1060\n",
    "- CPU : Intel CORE i5 8th Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d7cb9-40e9-49cc-8e97-4b78a8bfe7fe",
   "metadata": {},
   "source": [
    "## Library version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civilian-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Python & library version --------------------------\n",
      "Python version: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 1.5.2\n",
      "numpy version: 1.21.6\n",
      "matplotlib version: 3.5.2\n",
      "tqdm version: 4.65.2\n",
      "xgboost version: 1.7.2\n",
      "lightgbm version: 3.3.5\n",
      "seaborn version: 0.11.2\n",
      "scikit-learn version: 1.1.3\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tqdm as tq\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"-------------------------- Python & library version --------------------------\")\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"numpy version: {}\".format(np.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"tqdm version: {}\".format(tq.__version__))\n",
    "print(\"xgboost version: {}\".format(xgb.__version__))\n",
    "print(\"lightgbm version: {}\".format(lgb.__version__))\n",
    "print(\"seaborn version: {}\".format(sns.__version__))\n",
    "print(\"scikit-learn version: {}\".format(skl.__version__))\n",
    "print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156dcef-65d2-46a5-8bf6-1ddaa9f00f84",
   "metadata": {},
   "source": [
    "## 0. load the libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5e25e-f9a1-4980-ac53-6cdb73b3d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b09e2-4ff2-426a-a11d-7512ef73265b",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74194b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BDI 외부데이터 load & preprocessing\n",
    "bdi_data = pd.read_csv('./data/bdi.csv')\n",
    "\n",
    "#예시 데이터프레임 생성 (2014년 8월 29일부터 2023년 2월 27일까지의 데이터)\n",
    "start_date = datetime(2014, 8, 29)\n",
    "end_date = datetime(2023, 2, 27)\n",
    "\n",
    "#생성할 DataFrame 초기화\n",
    "date_list = []\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    date_list.append(current_date)\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "df = pd.DataFrame({'Date': date_list})\n",
    "\n",
    "#인덱스 추가\n",
    "df['Index'] = range(len(df))\n",
    "\n",
    "#datetime 형식으로 바꿔주기 위해 문자열 재지정\n",
    "bdi_data['Date'] = bdi_data['Date'].str.replace('/', '-')\n",
    "bdi_data['Date'] = pd.to_datetime(bdi_data['Date'])\n",
    "\n",
    "#dataframe columns rename\n",
    "bdi_data.columns = ['Date','bdi_price','start','high','low','volume','moving']\n",
    "\n",
    "#train, test에 merge 시킬 dataframe 생성\n",
    "bdi_dataframe = pd.merge(df['Date'], bdi_data[['Date','bdi_price']], on='Date', how='outer').sort_values(by='Date')\n",
    "\n",
    "#bdi 데이터에는 토,일 데이터가 존재하지 않으므로 금요일 값으로 대체\n",
    "bdi_dataframe.fillna(method='ffill', inplace=True)\n",
    "\n",
    "#bdi_price 데이터 타입변경\n",
    "bdi_dataframe['bdi_price'] = [float(value.replace(',', '')) for value in bdi_dataframe['bdi_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수입,수출 외부데이터 load & preprocessing\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "data = pd.read_csv('./data/최종데이터.csv')\n",
    "data['Date'] = data['Date'] + '-01'\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "#한달씩 미뤄주기(예를들어, 2015년 3월에 해당하는 데이터들을 ATA시점이 2015년 4월인 train,test 데이터에 병합시켜주기 위함)\n",
    "data['merge_date'] = data['Date'] + data['Date'].apply(lambda x: relativedelta(months=1))\n",
    "data['merge_date'] = pd.to_datetime(data['merge_date'])\n",
    "data['year'] = data['merge_date'].dt.year\n",
    "data['month'] = data['merge_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950e8b3",
   "metadata": {},
   "source": [
    "## 2. EDA & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA전 datetime 컬럼 처리\n",
    "train['ATA'] = pd.to_datetime(train['ATA'])\n",
    "test['ATA'] = pd.to_datetime(test['ATA'])\n",
    "\n",
    "# datetime을 여러 파생 변수로 변환\n",
    "for df in [train, test]:\n",
    "    df['year'] = df['ATA'].dt.year\n",
    "    df['month'] = df['ATA'].dt.month\n",
    "    df['day'] = df['ATA'].dt.day\n",
    "    df['hour'] = df['ATA'].dt.hour\n",
    "    df['minute'] = df['ATA'].dt.minute\n",
    "    df['weekday'] = df['ATA'].dt.weekday\n",
    "    df['weekofyear'] = df['ATA'].dt.weekofyear\n",
    "\n",
    "# datetime 컬럼 제거\n",
    "train.drop(columns='ATA', inplace=True)\n",
    "test.drop(columns='ATA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60803a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BDI 외부데이터 병합\n",
    "bdi_dataframe['Date'] = pd.to_datetime(bdi_dataframe['Date'])\n",
    "\n",
    "#ATA기준 전날의 값으로 병합시켜주기 위해 전처리(수입,수출 데이터와 같은 맥락)\n",
    "bdi_dataframe['merge_date'] = bdi_dataframe['Date'] + pd.to_timedelta(1, unit='d')\n",
    "\n",
    "# datetime을 여러 파생 변수로 변환\n",
    "bdi_dataframe['year'] = bdi_dataframe['merge_date'].dt.year\n",
    "bdi_dataframe['month'] = bdi_dataframe['merge_date'].dt.month\n",
    "bdi_dataframe['day'] = bdi_dataframe['merge_date'].dt.day\n",
    "\n",
    "bdi_dataframe = bdi_dataframe.drop(columns =['merge_date'])\n",
    "\n",
    "train = train.merge(bdi_dataframe, how = 'left', on = ['year','month','day'])\n",
    "test = test.merge(bdi_dataframe, how = 'left', on = ['year','month','day'])\n",
    "\n",
    "train.drop(columns=['Date'], inplace = True)\n",
    "test.drop(columns=['Date'], inplace = True)\n",
    "\n",
    "#예외 날짜에 대한 처리\n",
    "train['bdi_price'] = train['bdi_price'].fillna(0)\n",
    "test['bdi_price'] = test['bdi_price'].fillna(0)\n",
    "\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수입,수출 데이터 병합\n",
    "data = data.drop(columns =['merge_date'])\n",
    "data = data.drop(columns =['Date'])\n",
    "\n",
    "train = train.merge(data, how = 'left', on = ['year','month'])\n",
    "test = test.merge(data, how = 'left', on = ['year','month'])\n",
    "\n",
    "#예외 날짜에 대한 처리\n",
    "train.iloc[:,30:] = train.iloc[:,30:].fillna(0)\n",
    "test.iloc[:,29:] = test.iloc[:,29:].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06cff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#나라별 알맞은 데이터 할당\n",
    "train.loc[(train['ARI_CO']=='TW'),'수출금액']=train['대만_수출금액']\n",
    "train.loc[(train['ARI_CO']=='TW'),'수출증감률']=train['대만_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='TW'),'수입금액']=train['대만_수입금액']\n",
    "train.loc[(train['ARI_CO']=='TW'),'수입증감률']=train['대만_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='TW'),'무역수지']=train['대만_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='CN'),'수출금액']=train['중국_수출금액']\n",
    "train.loc[(train['ARI_CO']=='CN'),'수출증감률']=train['중국_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='CN'),'수입금액']=train['중국_수입금액']\n",
    "train.loc[(train['ARI_CO']=='CN'),'수입증감률']=train['중국_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='CN'),'무역수지']=train['중국_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='JP'),'수출금액']=train['일본_수출금액']\n",
    "train.loc[(train['ARI_CO']=='JP'),'수출증감률']=train['일본_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='JP'),'수입금액']=train['일본_수입금액']\n",
    "train.loc[(train['ARI_CO']=='JP'),'수입증감률']=train['일본_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='JP'),'무역수지']=train['일본_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='SG'),'수출금액']=train['싱가포르_수출금액']\n",
    "train.loc[(train['ARI_CO']=='SG'),'수출증감률']=train['싱가포르_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='SG'),'수입금액']=train['싱가포르_수입금액']\n",
    "train.loc[(train['ARI_CO']=='SG'),'수입증감률']=train['싱가포르_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='SG'),'무역수지']=train['싱가포르_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='AU'),'수출금액']=train['호주_수출금액']\n",
    "train.loc[(train['ARI_CO']=='AU'),'수출증감률']=train['호주_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='AU'),'수입금액']=train['호주_수입금액']\n",
    "train.loc[(train['ARI_CO']=='AU'),'수입증감률']=train['호주_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='AU'),'무역수지']=train['호주_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='IN'),'수출금액']=train['인도_수출금액']\n",
    "train.loc[(train['ARI_CO']=='IN'),'수출증감률']=train['인도_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='IN'),'수입금액']=train['인도_수입금액']\n",
    "train.loc[(train['ARI_CO']=='IN'),'수입증감률']=train['인도_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='IN'),'무역수지']=train['인도_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='RU'),'수출금액']=train['러시아_수출금액']\n",
    "train.loc[(train['ARI_CO']=='RU'),'수출증감률']=train['러시아_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='RU'),'수입금액']=train['러시아_수입금액']\n",
    "train.loc[(train['ARI_CO']=='RU'),'수입증감률']=train['러시아_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='RU'),'무역수지']=train['러시아_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='CA'),'수출금액']=train['캐나다_수출금액']\n",
    "train.loc[(train['ARI_CO']=='CA'),'수출증감률']=train['캐나다_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='CA'),'수입금액']=train['캐나다_수입금액']\n",
    "train.loc[(train['ARI_CO']=='CA'),'수입증감률']=train['캐나다_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='CA'),'무역수지']=train['캐나다_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='KR'),'수출금액']=train['한국_수출금액']\n",
    "train.loc[(train['ARI_CO']=='KR'),'수출증감률']=train['한국_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='KR'),'수입금액']=train['한국_수입금액']\n",
    "train.loc[(train['ARI_CO']=='KR'),'수입증감률']=train['한국_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='KR'),'무역수지']=train['한국_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='BR'),'수출금액']=train['브라질_수출금액']\n",
    "train.loc[(train['ARI_CO']=='BR'),'수출증감률']=train['브라질_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='BR'),'수입금액']=train['브라질_수입금액']\n",
    "train.loc[(train['ARI_CO']=='BR'),'수입증감률']=train['브라질_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='BR'),'무역수지']=train['브라질_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='ID'),'수출금액']=train['인도네시아_수출금액']\n",
    "train.loc[(train['ARI_CO']=='ID'),'수출증감률']=train['인도네시아_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='ID'),'수입금액']=train['인도네시아_수입금액']\n",
    "train.loc[(train['ARI_CO']=='ID'),'수입증감률']=train['인도네시아_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='ID'),'무역수지']=train['인도네시아_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='US'),'수출금액']=train['미국_수출금액']\n",
    "train.loc[(train['ARI_CO']=='US'),'수출증감률']=train['미국_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='US'),'수입금액']=train['미국_수입금액']\n",
    "train.loc[(train['ARI_CO']=='US'),'수입증감률']=train['미국_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='US'),'무역수지']=train['미국_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='UA'),'수출금액']=train['우크라이나_수출금액']\n",
    "train.loc[(train['ARI_CO']=='UA'),'수출증감률']=train['우크라이나_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='UA'),'수입금액']=train['우크라이나_수입금액']\n",
    "train.loc[(train['ARI_CO']=='UA'),'수입증감률']=train['우크라이나_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='UA'),'무역수지']=train['우크라이나_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='LV'),'수출금액']=train['라트비아_수출금액']\n",
    "train.loc[(train['ARI_CO']=='LV'),'수출증감률']=train['라트비아_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='LV'),'수입금액']=train['라트비아_수입금액']\n",
    "train.loc[(train['ARI_CO']=='LV'),'수입증감률']=train['라트비아_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='LV'),'무역수지']=train['라트비아_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='MZ'),'수출금액']=train['모잠비크_수출금액']\n",
    "train.loc[(train['ARI_CO']=='MZ'),'수출증감률']=train['모잠비크_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='MZ'),'수입금액']=train['모잠비크_수입금액']\n",
    "train.loc[(train['ARI_CO']=='MZ'),'수입증감률']=train['모잠비크_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='MZ'),'무역수지']=train['모잠비크_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='QA'),'수출금액']=train['카타르_수출금액']\n",
    "train.loc[(train['ARI_CO']=='QA'),'수출증감률']=train['카타르_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='QA'),'수입금액']=train['카타르_수입금액']\n",
    "train.loc[(train['ARI_CO']=='QA'),'수입증감률']=train['카타르_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='QA'),'무역수지']=train['카타르_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='ZA'),'수출금액']=train['남아프리카공화국_수출금액']\n",
    "train.loc[(train['ARI_CO']=='ZA'),'수출증감률']=train['남아프리카공화국_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='ZA'),'수입금액']=train['남아프리카공화국_수입금액']\n",
    "train.loc[(train['ARI_CO']=='ZA'),'수입증감률']=train['남아프리카공화국_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='ZA'),'무역수지']=train['남아프리카공화국_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='VN'),'수출금액']=train['베트남_수출금액']\n",
    "train.loc[(train['ARI_CO']=='VN'),'수출증감률']=train['베트남_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='VN'),'수입금액']=train['베트남_수입금액']\n",
    "train.loc[(train['ARI_CO']=='VN'),'수입증감률']=train['베트남_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='VN'),'무역수지']=train['베트남_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='TT'),'수출금액']=train['트리니다드토바고_수출금액']\n",
    "train.loc[(train['ARI_CO']=='TT'),'수출증감률']=train['트리니다드토바고_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='TT'),'수입금액']=train['트리니다드토바고_수입금액']\n",
    "train.loc[(train['ARI_CO']=='TT'),'수입증감률']=train['트리니다드토바고_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='TT'),'무역수지']=train['트리니다드토바고_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='PE'),'수출금액']=train['페루_수출금액']\n",
    "train.loc[(train['ARI_CO']=='PE'),'수출증감률']=train['페루_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='PE'),'수입금액']=train['페루_수입금액']\n",
    "train.loc[(train['ARI_CO']=='PE'),'수입증감률']=train['페루_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='PE'),'무역수지']=train['페루_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='MY'),'수출금액']=train['말레이시아_수출금액']\n",
    "train.loc[(train['ARI_CO']=='MY'),'수출증감률']=train['말레이시아_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='MY'),'수입금액']=train['말레이시아_수입금액']\n",
    "train.loc[(train['ARI_CO']=='MY'),'수입증감률']=train['말레이시아_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='MY'),'무역수지']=train['말레이시아_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='CL'),'수출금액']=train['칠레_수출금액']\n",
    "train.loc[(train['ARI_CO']=='CL'),'수출증감률']=train['칠레_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='CL'),'수입금액']=train['칠레_수입금액']\n",
    "train.loc[(train['ARI_CO']=='CL'),'수입증감률']=train['칠레_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='CL'),'무역수지']=train['칠레_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='FI'),'수출금액']=train['핀란드_수출금액']\n",
    "train.loc[(train['ARI_CO']=='FI'),'수출증감률']=train['핀란드_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='FI'),'수입금액']=train['핀란드_수입금액']\n",
    "train.loc[(train['ARI_CO']=='FI'),'수입증감률']=train['핀란드_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='FI'),'무역수지']=train['핀란드_무역수지']\n",
    "\n",
    "train.loc[(train['ARI_CO']=='PH'),'수출금액']=train['필리핀_수출금액']\n",
    "train.loc[(train['ARI_CO']=='PH'),'수출증감률']=train['필리핀_수출증감률']\n",
    "train.loc[(train['ARI_CO']=='PH'),'수입금액']=train['필리핀_수입금액']\n",
    "train.loc[(train['ARI_CO']=='PH'),'수입증감률']=train['필리핀_수입증감률']\n",
    "train.loc[(train['ARI_CO']=='PH'),'무역수지']=train['필리핀_무역수지']\n",
    "\n",
    "#예외 데이터 처리(Null 값 처리)\n",
    "train['수출금액'] = train['수출금액'].fillna(train['미국_수출금액'])\n",
    "train['수출증감률'] = train['수출증감률'].fillna(train['미국_수출증감률'])\n",
    "train['수입금액'] = train['수입금액'].fillna(train['미국_수입금액'])\n",
    "train['수입증감률'] = train['수입증감률'].fillna(train['미국_수입증감률'])\n",
    "train['무역수지'] = train['무역수지'].fillna(train['미국_무역수지'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2811b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[(test['ARI_CO']=='TW'),'수출금액']=test['대만_수출금액']\n",
    "test.loc[(test['ARI_CO']=='TW'),'수출증감률']=test['대만_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='TW'),'수입금액']=test['대만_수입금액']\n",
    "test.loc[(test['ARI_CO']=='TW'),'수입증감률']=test['대만_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='TW'),'무역수지']=test['대만_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='CN'),'수출금액']=test['중국_수출금액']\n",
    "test.loc[(test['ARI_CO']=='CN'),'수출증감률']=test['중국_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='CN'),'수입금액']=test['중국_수입금액']\n",
    "test.loc[(test['ARI_CO']=='CN'),'수입증감률']=test['중국_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='CN'),'무역수지']=test['중국_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='JP'),'수출금액']=test['일본_수출금액']\n",
    "test.loc[(test['ARI_CO']=='JP'),'수출증감률']=test['일본_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='JP'),'수입금액']=test['일본_수입금액']\n",
    "test.loc[(test['ARI_CO']=='JP'),'수입증감률']=test['일본_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='JP'),'무역수지']=test['일본_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='SG'),'수출금액']=test['싱가포르_수출금액']\n",
    "test.loc[(test['ARI_CO']=='SG'),'수출증감률']=test['싱가포르_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='SG'),'수입금액']=test['싱가포르_수입금액']\n",
    "test.loc[(test['ARI_CO']=='SG'),'수입증감률']=test['싱가포르_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='SG'),'무역수지']=test['싱가포르_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='AU'),'수출금액']=test['호주_수출금액']\n",
    "test.loc[(test['ARI_CO']=='AU'),'수출증감률']=test['호주_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='AU'),'수입금액']=test['호주_수입금액']\n",
    "test.loc[(test['ARI_CO']=='AU'),'수입증감률']=test['호주_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='AU'),'무역수지']=test['호주_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='IN'),'수출금액']=test['인도_수출금액']\n",
    "test.loc[(test['ARI_CO']=='IN'),'수출증감률']=test['인도_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='IN'),'수입금액']=test['인도_수입금액']\n",
    "test.loc[(test['ARI_CO']=='IN'),'수입증감률']=test['인도_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='IN'),'무역수지']=test['인도_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='RU'),'수출금액']=test['러시아_수출금액']\n",
    "test.loc[(test['ARI_CO']=='RU'),'수출증감률']=test['러시아_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='RU'),'수입금액']=test['러시아_수입금액']\n",
    "test.loc[(test['ARI_CO']=='RU'),'수입증감률']=test['러시아_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='RU'),'무역수지']=test['러시아_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='CA'),'수출금액']=test['캐나다_수출금액']\n",
    "test.loc[(test['ARI_CO']=='CA'),'수출증감률']=test['캐나다_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='CA'),'수입금액']=test['캐나다_수입금액']\n",
    "test.loc[(test['ARI_CO']=='CA'),'수입증감률']=test['캐나다_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='CA'),'무역수지']=test['캐나다_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='KR'),'수출금액']=test['한국_수출금액']\n",
    "test.loc[(test['ARI_CO']=='KR'),'수출증감률']=test['한국_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='KR'),'수입금액']=test['한국_수입금액']\n",
    "test.loc[(test['ARI_CO']=='KR'),'수입증감률']=test['한국_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='KR'),'무역수지']=test['한국_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='BR'),'수출금액']=test['브라질_수출금액']\n",
    "test.loc[(test['ARI_CO']=='BR'),'수출증감률']=test['브라질_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='BR'),'수입금액']=test['브라질_수입금액']\n",
    "test.loc[(test['ARI_CO']=='BR'),'수입증감률']=test['브라질_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='BR'),'무역수지']=test['브라질_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='ID'),'수출금액']=test['인도네시아_수출금액']\n",
    "test.loc[(test['ARI_CO']=='ID'),'수출증감률']=test['인도네시아_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='ID'),'수입금액']=test['인도네시아_수입금액']\n",
    "test.loc[(test['ARI_CO']=='ID'),'수입증감률']=test['인도네시아_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='ID'),'무역수지']=test['인도네시아_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='US'),'수출금액']=test['미국_수출금액']\n",
    "test.loc[(test['ARI_CO']=='US'),'수출증감률']=test['미국_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='US'),'수입금액']=test['미국_수입금액']\n",
    "test.loc[(test['ARI_CO']=='US'),'수입증감률']=test['미국_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='US'),'무역수지']=test['미국_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='UA'),'수출금액']=test['우크라이나_수출금액']\n",
    "test.loc[(test['ARI_CO']=='UA'),'수출증감률']=test['우크라이나_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='UA'),'수입금액']=test['우크라이나_수입금액']\n",
    "test.loc[(test['ARI_CO']=='UA'),'수입증감률']=test['우크라이나_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='UA'),'무역수지']=test['우크라이나_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='LV'),'수출금액']=test['라트비아_수출금액']\n",
    "test.loc[(test['ARI_CO']=='LV'),'수출증감률']=test['라트비아_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='LV'),'수입금액']=test['라트비아_수입금액']\n",
    "test.loc[(test['ARI_CO']=='LV'),'수입증감률']=test['라트비아_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='LV'),'무역수지']=test['라트비아_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='MZ'),'수출금액']=test['모잠비크_수출금액']\n",
    "test.loc[(test['ARI_CO']=='MZ'),'수출증감률']=test['모잠비크_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='MZ'),'수입금액']=test['모잠비크_수입금액']\n",
    "test.loc[(test['ARI_CO']=='MZ'),'수입증감률']=test['모잠비크_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='MZ'),'무역수지']=test['모잠비크_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='QA'),'수출금액']=test['카타르_수출금액']\n",
    "test.loc[(test['ARI_CO']=='QA'),'수출증감률']=test['카타르_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='QA'),'수입금액']=test['카타르_수입금액']\n",
    "test.loc[(test['ARI_CO']=='QA'),'수입증감률']=test['카타르_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='QA'),'무역수지']=test['카타르_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='ZA'),'수출금액']=test['남아프리카공화국_수출금액']\n",
    "test.loc[(test['ARI_CO']=='ZA'),'수출증감률']=test['남아프리카공화국_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='ZA'),'수입금액']=test['남아프리카공화국_수입금액']\n",
    "test.loc[(test['ARI_CO']=='ZA'),'수입증감률']=test['남아프리카공화국_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='ZA'),'무역수지']=test['남아프리카공화국_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='VN'),'수출금액']=test['베트남_수출금액']\n",
    "test.loc[(test['ARI_CO']=='VN'),'수출증감률']=test['베트남_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='VN'),'수입금액']=test['베트남_수입금액']\n",
    "test.loc[(test['ARI_CO']=='VN'),'수입증감률']=test['베트남_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='VN'),'무역수지']=test['베트남_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='TT'),'수출금액']=test['트리니다드토바고_수출금액']\n",
    "test.loc[(test['ARI_CO']=='TT'),'수출증감률']=test['트리니다드토바고_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='TT'),'수입금액']=test['트리니다드토바고_수입금액']\n",
    "test.loc[(test['ARI_CO']=='TT'),'수입증감률']=test['트리니다드토바고_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='TT'),'무역수지']=test['트리니다드토바고_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='PE'),'수출금액']=test['페루_수출금액']\n",
    "test.loc[(test['ARI_CO']=='PE'),'수출증감률']=test['페루_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='PE'),'수입금액']=test['페루_수입금액']\n",
    "test.loc[(test['ARI_CO']=='PE'),'수입증감률']=test['페루_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='PE'),'무역수지']=test['페루_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='MY'),'수출금액']=test['말레이시아_수출금액']\n",
    "test.loc[(test['ARI_CO']=='MY'),'수출증감률']=test['말레이시아_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='MY'),'수입금액']=test['말레이시아_수입금액']\n",
    "test.loc[(test['ARI_CO']=='MY'),'수입증감률']=test['말레이시아_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='MY'),'무역수지']=test['말레이시아_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='CL'),'수출금액']=test['칠레_수출금액']\n",
    "test.loc[(test['ARI_CO']=='CL'),'수출증감률']=test['칠레_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='CL'),'수입금액']=test['칠레_수입금액']\n",
    "test.loc[(test['ARI_CO']=='CL'),'수입증감률']=test['칠레_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='CL'),'무역수지']=test['칠레_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='FI'),'수출금액']=test['핀란드_수출금액']\n",
    "test.loc[(test['ARI_CO']=='FI'),'수출증감률']=test['핀란드_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='FI'),'수입금액']=test['핀란드_수입금액']\n",
    "test.loc[(test['ARI_CO']=='FI'),'수입증감률']=test['핀란드_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='FI'),'무역수지']=test['핀란드_무역수지']\n",
    "\n",
    "test.loc[(test['ARI_CO']=='PH'),'수출금액']=test['필리핀_수출금액']\n",
    "test.loc[(test['ARI_CO']=='PH'),'수출증감률']=test['필리핀_수출증감률']\n",
    "test.loc[(test['ARI_CO']=='PH'),'수입금액']=test['필리핀_수입금액']\n",
    "test.loc[(test['ARI_CO']=='PH'),'수입증감률']=test['필리핀_수입증감률']\n",
    "test.loc[(test['ARI_CO']=='PH'),'무역수지']=test['필리핀_무역수지']\n",
    "\n",
    "test['수출금액'] = test['수출금액'].fillna(test['미국_수출금액'])\n",
    "test['수출증감률'] = test['수출증감률'].fillna(test['미국_수출증감률'])\n",
    "test['수입금액'] = test['수입금액'].fillna(test['미국_수입금액'])\n",
    "test['수입증감률'] = test['수입증감률'].fillna(test['미국_수입증감률'])\n",
    "test['무역수지'] = test['무역수지'].fillna(test['미국_무역수지'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수출금액,수출증감률,수입금액,수입증감률,무역수지 columns만 사용\n",
    "columns_list_tr = train.columns[:30].to_list() + train.columns[-5:].to_list()\n",
    "train = train[columns_list_tr]\n",
    "columns_list_te = train.drop(columns=['CI_HOUR']).columns.to_list()\n",
    "test = test[columns_list_te]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77331ac4",
   "metadata": {},
   "source": [
    "### 2-1. Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ad9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시각화 설정\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 15\n",
    "# 사용자 운영체제 확인\n",
    "os.name\n",
    "\n",
    "# 운영체제별 한글 폰트 설정\n",
    "if os.name == 'posix': # Mac 환경 폰트 설정\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif os.name == 'nt': # Windows 환경 폰트 설정\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "plt.rc('axes', unicode_minus=False) # 마이너스 폰트 설정\n",
    "\n",
    "# 글씨 선명하게 출력하는 설정\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc187372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target distribuition\n",
    "plt.figure(figsize=(10,10))\n",
    "x = train['CI_HOUR']\n",
    "sns.kdeplot(x)\n",
    "plt.title(\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['CI_HOUR'].describe()\n",
    "#매우 skew가 높은 분포이므로 후에 log변환등 정규화 과정이 필요할 수 있다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target distribuition(not zero)\n",
    "plt.figure(figsize=(10,10))\n",
    "x = train[train['CI_HOUR'] != 0]['CI_HOUR']\n",
    "sns.kdeplot(x)\n",
    "plt.title(\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['CI_HOUR'] != 0]['CI_HOUR'].describe()\n",
    "#0 제외한 값에 대해서도 표준편차가 매우 크고 skew가 큰 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['CI_HOUR'].value_counts()\n",
    "#0이 매우 많은 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4325864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIST가 0인 경우 Target 값이 대부분 0이므로 그 외의 데이터들은 이상치로 판단 > Target값 0으로 대체\n",
    "train.loc[(train['DIST'] == 0) & (train['CI_HOUR'] > 0), 'CI_HOUR'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72d669",
   "metadata": {},
   "source": [
    "### 2-2. NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREADTH, DEPTH, DRAUGHT, LENGTH NaN Row\n",
    "train[train['BREADTH'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf0c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선박의 DEADWEIGHT(재화중량톤수), GT(용적톤수) 및 FLAG(국적)에 따라 BREADTH, DEPTH, DRAUGHT, LENGTH 결측치 대체\n",
    "train[(train['DEADWEIGHT'] == 1500) & (train['GT'] == 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['BREADTH'].isna(), 'BREADTH'] = 10.0\n",
    "train.loc[train['DEPTH'].isna(), 'DEPTH'] = 10.0\n",
    "train.loc[train['DRAUGHT'].isna(), 'DRAUGHT'] = 0.0\n",
    "train.loc[train['LENGTH'].isna(), 'LENGTH'] = 70.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CGT\n",
    "con_cargo = ['Container','Cargo']\n",
    "train.loc[(train['DEADWEIGHT']>=250000)  & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 0.25\n",
    "train.loc[(train['DEADWEIGHT']>=160000) & (train['DEADWEIGHT']<250000) & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 0.3\n",
    "train.loc[(train['DEADWEIGHT']>=80000) & (train['DEADWEIGHT']<160000) & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 0.4\n",
    "train.loc[(train['DEADWEIGHT']>=50000) & (train['DEADWEIGHT']<80000) & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 0.5\n",
    "train.loc[(train['DEADWEIGHT']>=30000) & (train['DEADWEIGHT']<50000) & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 0.65\n",
    "train.loc[(train['DEADWEIGHT']>=10000) & (train['DEADWEIGHT']<30000) & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 0.75\n",
    "train.loc[(train['DEADWEIGHT']>=4000) & (train['DEADWEIGHT']<10000) & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 1.15\n",
    "train.loc[(train['DEADWEIGHT']<4000)  & (train['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=train['DEADWEIGHT'] * 1.7\n",
    "\n",
    "train.loc[(train['DEADWEIGHT']>=160000)  & (train['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=train['DEADWEIGHT'] * 0.3\n",
    "train.loc[(train['DEADWEIGHT']>=80000) & (train['DEADWEIGHT']<160000) & (train['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=train['DEADWEIGHT'] * 0.4\n",
    "train.loc[(train['DEADWEIGHT']>=50000) & (train['DEADWEIGHT']<80000) & (train['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=train['DEADWEIGHT'] * 0.5\n",
    "train.loc[(train['DEADWEIGHT']>=30000) & (train['DEADWEIGHT']<50000) & (train['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=train['DEADWEIGHT'] * 0.6\n",
    "train.loc[(train['DEADWEIGHT']>=10000) & (train['DEADWEIGHT']<30000) & (train['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=train['DEADWEIGHT'] * 0.7\n",
    "train.loc[(train['DEADWEIGHT']>=4000) & (train['DEADWEIGHT']<10000) & (train['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=train['DEADWEIGHT'] * 1.1\n",
    "train.loc[(train['DEADWEIGHT']<4000)  & (train['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=train['DEADWEIGHT'] * 1.6\n",
    "\n",
    "train.loc[(train['DEADWEIGHT']>=10000)  & (train['SHIP_TYPE_CATEGORY'].isin(con_cargo)),'CGT']=train['DEADWEIGHT'] * 1.25\n",
    "train.loc[(train['DEADWEIGHT']>=4000) & (train['DEADWEIGHT']<10000) & (train['SHIP_TYPE_CATEGORY'].isin(con_cargo)),'CGT']=train['DEADWEIGHT'] * 1.5\n",
    "train.loc[(train['DEADWEIGHT']<4000)  & (train['SHIP_TYPE_CATEGORY'].isin(con_cargo)),'CGT']=train['DEADWEIGHT'] * 2.05\n",
    "\n",
    "#위에 해당하지 않는 값에 대한 처리(해당 Row의 DEADWEIGHT값으로 대체)\n",
    "train['CGT'].fillna(train['DEADWEIGHT'], inplace=True)\n",
    "\n",
    "test.loc[(test['DEADWEIGHT']>=250000)  & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 0.25\n",
    "test.loc[(test['DEADWEIGHT']>=160000) & (test['DEADWEIGHT']<250000) & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 0.3\n",
    "test.loc[(test['DEADWEIGHT']>=80000) & (test['DEADWEIGHT']<160000) & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 0.4\n",
    "test.loc[(test['DEADWEIGHT']>=50000) & (test['DEADWEIGHT']<80000) & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 0.5\n",
    "test.loc[(test['DEADWEIGHT']>=30000) & (test['DEADWEIGHT']<50000) & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 0.65\n",
    "test.loc[(test['DEADWEIGHT']>=10000) & (test['DEADWEIGHT']<30000) & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 0.75\n",
    "test.loc[(test['DEADWEIGHT']>=4000) & (test['DEADWEIGHT']<10000) & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 1.15\n",
    "test.loc[(test['DEADWEIGHT']<4000)  & (test['SHIP_TYPE_CATEGORY']=='Tanker'),'CGT']=test['DEADWEIGHT'] * 1.7\n",
    "\n",
    "\n",
    "test.loc[(test['DEADWEIGHT']>=160000)  & (test['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=test['DEADWEIGHT'] * 0.3\n",
    "test.loc[(test['DEADWEIGHT']>=80000) & (test['DEADWEIGHT']<160000) & (test['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=test['DEADWEIGHT'] * 0.4\n",
    "test.loc[(test['DEADWEIGHT']>=50000) & (test['DEADWEIGHT']<80000) & (test['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=test['DEADWEIGHT'] * 0.5\n",
    "test.loc[(test['DEADWEIGHT']>=30000) & (test['DEADWEIGHT']<50000) & (test['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=test['DEADWEIGHT'] * 0.6\n",
    "test.loc[(test['DEADWEIGHT']>=10000) & (test['DEADWEIGHT']<30000) & (test['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=test['DEADWEIGHT'] * 0.7\n",
    "test.loc[(test['DEADWEIGHT']>=4000) & (test['DEADWEIGHT']<10000) & (test['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=test['DEADWEIGHT'] * 1.1\n",
    "test.loc[(test['DEADWEIGHT']<4000)  & (test['SHIP_TYPE_CATEGORY']=='Bulk'),'CGT']=test['DEADWEIGHT'] * 1.6\n",
    "\n",
    "\n",
    "test.loc[(test['DEADWEIGHT']>=10000)  & (test['SHIP_TYPE_CATEGORY'].isin(con_cargo)),'CGT']=test['DEADWEIGHT'] * 1.25\n",
    "test.loc[(test['DEADWEIGHT']>=4000) & (test['DEADWEIGHT']<10000) & (test['SHIP_TYPE_CATEGORY'].isin(con_cargo)),'CGT']=test['DEADWEIGHT'] * 1.5\n",
    "test.loc[(test['DEADWEIGHT']<4000)  & (test['SHIP_TYPE_CATEGORY'].isin(con_cargo)),'CGT']=test['DEADWEIGHT'] * 2.05\n",
    "\n",
    "test['CGT'].fillna(test['DEADWEIGHT'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77566eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#나라_항구 컬럼 생성\n",
    "train['ARI_INFO'] = train['ARI_CO'] + '_' + train['ARI_PO']\n",
    "test['ARI_INFO'] = test['ARI_CO'] + '_' + test['ARI_PO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af0a0e",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIST가 0인 데이터들을 함께 학습시, 학습이 잘 안되는 점을 보완하기 위해 DIST가 0이 아닌 데이터들만 사용하여 학습 진행\n",
    "train['DIST'] = train['DIST'].fillna(0)\n",
    "test['DIST'] = test['DIST'].fillna(0)\n",
    "\n",
    "train = train.loc[(train['DIST'] != 0), ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a406bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#나라별 공휴일\n",
    "import holidays\n",
    "\n",
    "##나라별 공휴일 변수지정(TT,QA는 holidays 라이브러리로 처리 불가능하므로 따로 진행)\n",
    "CN_holidays = holidays.CN()\n",
    "JP_holidays = holidays.JP()\n",
    "RU_holidays = holidays.RU()\n",
    "AU_holidays = holidays.AU()\n",
    "SG_holidays = holidays.SG()\n",
    "ZA_holidays = holidays.ZA()\n",
    "KR_holidays = holidays.KR()\n",
    "TW_holidays = holidays.TW()\n",
    "#TT_holidays = holidays.TT()\n",
    "ID_holidays = holidays.ID()\n",
    "BR_holidays = holidays.BR()\n",
    "#QA_holidays = holidays.QA()\n",
    "LV_holidays = holidays.LV()\n",
    "MZ_holidays = holidays.MZ()\n",
    "US_holidays = holidays.US()\n",
    "IN_holidays = holidays.IN()\n",
    "UA_holidays = holidays.UA()\n",
    "CA_holidays = holidays.CA()\n",
    "MY_holidays = holidays.MY()\n",
    "PE_holidays = holidays.PE()\n",
    "VN_holidays = holidays.VN()\n",
    "FI_holidays = holidays.FI()\n",
    "CL_holidays = holidays.CL()\n",
    "VE_holidays = holidays.VE()\n",
    "PH_holidays = holidays.PH()\n",
    "\n",
    "##나라코드 리스트 생성\n",
    "country_list = list(train['ARI_CO'].unique())\n",
    "country_list.remove('TT')\n",
    "country_list.remove('QA')\n",
    "\n",
    "##나라별 공휴일 리스트 생성\n",
    "holiday_list = [CN_holidays,JP_holidays,RU_holidays,AU_holidays,SG_holidays,\n",
    "                ZA_holidays,KR_holidays,TW_holidays,ID_holidays,BR_holidays,\n",
    "                LV_holidays,MZ_holidays,US_holidays,IN_holidays,UA_holidays,\n",
    "                CA_holidays,MY_holidays,PE_holidays,VN_holidays,FI_holidays,\n",
    "                CL_holidays,VE_holidays,PH_holidays]\n",
    "\n",
    "##공휴일 피처생성\n",
    "train['date'] = train['year'].astype(str) + '-' + train['month'].astype(str) + '-' + train['day'].astype(str)\n",
    "test['date'] = test['year'].astype(str) + '-' + test['month'].astype(str) + '-' + test['day'].astype(str)\n",
    "\n",
    "train['holiday'] = 0\n",
    "test['holiday'] = 0\n",
    "for i in tqdm(range(len(holiday_list))):\n",
    "    train.loc[train['ARI_CO'] == country_list[i], \"holiday\"] = train.loc[train['ARI_CO'] == country_list[i], \"date\"].apply(lambda x : 1 if x in holiday_list[i] else 0)\n",
    "    test.loc[test['ARI_CO'] == country_list[i], \"holiday\"] = test.loc[test['ARI_CO'] == country_list[i], \"date\"].apply(lambda x : 1 if x in holiday_list[i] else 0)\n",
    "    \n",
    "###트리니다드 토바고(TT) - 구글 Bard를 이용해 얻은 도메인 지식을 활용\n",
    "TT_holiday = ['2014-11-1','2014-12-25','2014-12-26',\n",
    "              '2015-1-1','2015-1-2','2015-1-25','2015-1-26','2015-1-27','2015-2-27','2015-3-8','2015-4-3','2015-4-6','2015-5-1','2015-5-22','2015-6-18','2015-8-3','2015-8-4','2015-11-1','2015-12-25','2015-12-26',\n",
    "             '2016-1-1','2016-1-2','2016-1-24','2016-1-25','2016-1-26','2016-2-26','2016-3-8','2016-3-25','2016-3-28','2016-5-1','2016-5-22','2016-6-17','2016-8-3','2016-8-4','2016-11-1','2016-12-25','2016-12-26',\n",
    "             '2017-1-1','2017-1-2','2017-1-23','2017-1-24','2017-1-25','2017-2-25','2017-3-8','2017-4-14','2017-4-17','2017-5-1','2017-5-22','2017-6-16','2017-8-3','2017-8-4','2017-11-1','2017-12-25','2017-12-26',\n",
    "             '2018-1-1','2018-1-2','2018-1-22','2018-1-23','2018-1-24','2018-2-24','2018-3-8','2018-4-13','2018-4-16','2018-5-1','2018-5-22','2018-6-15','2018-8-3','2018-8-4','2018-11-1','2018-12-25','2018-12-26',\n",
    "             '2019-1-1','2019-1-2','2019-1-21','2019-1-22','2019-1-23','2019-2-23','2019-3-8','2019-4-19','2019-4-22','2019-5-1','2019-5-22','2019-6-14','2019-8-3','2019-8-4','2019-11-1','2019-12-25','2019-12-26',\n",
    "             '2020-1-1','2020-1-2','2020-1-20','2020-1-21','2020-1-22','2020-2-22','2020-3-8','2020-4-10','2020-4-13','2020-5-1','2020-5-22','2020-6-13','2020-8-3','2020-8-4','2020-11-1','2020-12-25','2020-12-26',\n",
    "             '2021-1-1','2021-1-2','2021-1-19','2021-1-20','2021-1-21','2021-2-21','2021-3-8','2021-4-2','2021-4-5','2021-5-1','2021-5-22','2021-6-12','2021-8-3','2021-8-4','2021-11-1','2021-12-25','2021-12-26',\n",
    "             '2022-1-1','2022-1-2','2022-1-18','2022-1-19','2022-1-20','2022-2-20','2022-3-8','2022-4-7','2022-4-10','2022-5-1','2022-5-22','2022-6-11','2022-8-3','2022-8-4','2022-11-1','2022-12-25','2022-12-26',\n",
    "             '2023-1-1','2023-1-2','2023-1-17','2023-1-18','2023-1-19','2023-2-19']\n",
    "train.loc[train['ARI_CO'] == \"TT\", \"holiday\"] = train.loc[train['ARI_CO'] == \"TT\", \"date\"].apply(lambda x : 1 if x in TT_holiday else 0)  \n",
    "test.loc[test['ARI_CO'] == \"TT\", \"holiday\"] = test.loc[test['ARI_CO'] == \"TT\", \"date\"].apply(lambda x : 1 if x in TT_holiday else 0)  \n",
    "\n",
    "###카타르(QA) - 구글 Bard를 이용해 얻은 도메인 지식을 활용\n",
    "QA_holiday = ['2014-9-22','2014-9-23','2014-9-24','2014-12-25','2014-12-26',\n",
    "             '2015-1-1','2015-1-2','2015-7-17','2015-7-18','2015-7-19','2015-9-21','2015-9-22','2015-9-23','2015-12-25','2015-12-26',\n",
    "             '2016-1-1','2016-1-2','2016-7-10','2016-7-11','2016-7-12','2016-9-24','2016-9-25','2016-9-26','2016-12-25','2016-12-26',\n",
    "             '2017-1-1','2017-1-2','2017-7-7','2017-7-8','2017-7-9','2017-9-22','2017-9-23','2017-9-24','2017-12-25','2017-12-26',\n",
    "             '2018-1-1','2018-1-2','2018-7-14','2018-7-15','2018-7-16','2018-9-29','2018-9-30','2018-10-1','2018-12-25','2018-12-26',\n",
    "             '2019-1-1','2019-1-2','2019-7-12','2019-7-13','2019-7-14','2019-9-27','2019-9-28','2019-9-29','2019-12-25','2019-12-26',\n",
    "             '2020-1-1','2020-1-2','2020-5-27','2020-6-23','2020-6-24','2020-6-25','2020-7-31','2020-8-1','2020-8-2','2020-12-25','2020-12-26',\n",
    "             '2021-1-1','2021-1-2','2021-5-27','2021-7-20','2021-7-21','2021-7-22','2021-9-10','2021-9-11','2021-9-12','2021-12-25','2021-12-26',\n",
    "             '2022-1-1','2022-1-2','2022-5-27','2022-7-10','2022-7-11','2022-7-12','2022-9-24','2022-9-25','2022-9-26','2022-12-25','2022-12-26',\n",
    "             '2023-1-1','2023-1-2']\n",
    "train.loc[train['ARI_CO'] == \"QA\", \"holiday\"] = train.loc[train['ARI_CO'] == \"QA\", \"date\"].apply(lambda x : 1 if x in QA_holiday else 0)  \n",
    "test.loc[test['ARI_CO'] == \"QA\", \"holiday\"] = test.loc[test['ARI_CO'] == \"QA\", \"date\"].apply(lambda x : 1 if x in QA_holiday else 0)\n",
    "\n",
    "#Null 값 처리(다른 나라 및 날짜에 대한 처리)\n",
    "train['holiday'] = train['holiday'].fillna(0)\n",
    "test['holiday'] = test['holiday'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_covid(df):\n",
    "    df['group_covid'] = '-' \n",
    "    df.loc[(df['year'] <= 2019), 'group_covid'] = 'prior_covid'\n",
    "    df.loc[(df['year'] >= 2020) & (df['year'] < 2023), 'group_covid'] = 'pro_covid'\n",
    "    df.loc[(df['year'] >= 2023), 'group_covid'] = 'after_covid'\n",
    "    df.loc[(df['group_covid'] == '-'), 'group_covid'] = 'Na'\n",
    "    return df['group_covid']\n",
    "\n",
    "def group_season(df):\n",
    "    df['group_season'] = '-'\n",
    "    df.loc[(df['month'] == 3) | (df['month'] == 4) | (df['month'] == 5), 'group_season'] = 'season_1'\n",
    "    df.loc[(df['month'] == 6) | (df['month'] == 7) | (df['month'] == 8), 'group_season'] = 'season_2'\n",
    "    df.loc[(df['month'] == 9) | (df['month'] == 10) | (df['month'] == 11), 'group_season'] = 'season_3'\n",
    "    df.loc[(df['month'] == 12) | (df['month'] == 1) | (df['month'] == 2), 'group_season'] = 'season_4'\n",
    "    df.loc[(df['group_season'] == '-'), 'group_season'] = 'Na'\n",
    "    return df['group_season']\n",
    "\n",
    "def group_day(df):\n",
    "    df['group_day'] = '-' \n",
    "    df.loc[(df['day'] < 10), 'group_day'] = 'start_month'\n",
    "    df.loc[(df['day'] >= 10) & (df['day'] < 21), 'group_day'] = 'middle_month'\n",
    "    df.loc[(df['day'] >= 21) & (df['day'] <= 31), 'group_day'] = 'finish_month'\n",
    "    df.loc[(df['group_day'] == '-'), 'group_day'] = 'Na'\n",
    "    return df['group_day']\n",
    "\n",
    "def group_time(df):\n",
    "    df['group_time'] = '-' \n",
    "    df.loc[(df['ATA_LT'] < 5), 'group_time'] = 'dawn'\n",
    "    df.loc[(df['ATA_LT'] >= 5) & (df['ATA_LT'] < 11), 'group_time'] = 'morning'\n",
    "    df.loc[(df['ATA_LT'] >= 11) & (df['ATA_LT'] < 18), 'group_time'] = 'afternoon'\n",
    "    df.loc[(df['ATA_LT'] >= 18) & (df['ATA_LT'] <= 23), 'group_time'] = 'dinner'\n",
    "    df.loc[(df['group_time'] == '-'), 'group_time'] = 'Na'\n",
    "    return df['group_time']\n",
    "\n",
    "def group_built(df):\n",
    "    df['group_built'] = '-' \n",
    "    df.loc[(df['BUILT'] < 10), 'group_built'] = 'age_1'\n",
    "    df.loc[(df['BUILT'] >= 10) & (df['BUILT'] < 20), 'group_built'] = 'age_2'\n",
    "    df.loc[(df['BUILT'] >= 20) & (df['BUILT'] < 30), 'group_built'] = 'age_3'\n",
    "    df.loc[(df['BUILT'] >= 40) & (df['BUILT'] < 50), 'group_built'] = 'age_4'\n",
    "    df.loc[(df['BUILT'] >= 50) & (df['BUILT'] < 60), 'group_built'] = 'age_5'\n",
    "    df.loc[(df['BUILT'] >= 60) & (df['BUILT'] < 70), 'group_built'] = 'age_6'\n",
    "    df.loc[(df['BUILT'] >= 70) & (df['BUILT'] <= 80), 'group_built'] = 'age_7'\n",
    "    df.loc[(df['group_built'] == '-'), 'group_built'] = 'Na'\n",
    "    return df['group_built']\n",
    "\n",
    "def log_DIST(df):\n",
    "    df['log_DIST'] = 0\n",
    "    df['log_DIST'] = np.log1p(df['DIST'])\n",
    "    return df['log_DIST']\n",
    "\n",
    "def DIST_LENGTH(df):\n",
    "    df['DIST_LENGTH'] = 0\n",
    "    df['DIST_LENGTH'] = df['DIST']/df['LENGTH']\n",
    "    return df['DIST_LENGTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(train, test):\n",
    "    \n",
    "    start = datetime.now()\n",
    "    print('Start time: ', start)\n",
    "    \n",
    "    train['year_month'] = train['year'].astype(str) + '_' + train['month'].astype(str)\n",
    "    train['group_covid'] = group_covid(train)\n",
    "    train['group_season'] = group_season(train)\n",
    "    train['group_day'] = group_day(train)\n",
    "    train['group_time'] = group_time(train)\n",
    "    train['group_built'] = group_built(train)\n",
    "    train['log_DIST'] = log_DIST(train)\n",
    "    train['DIST_LENGTH'] = DIST_LENGTH(train)\n",
    "    \n",
    "    print('Train dataset success !')\n",
    "    \n",
    "    test['year_month'] = test['year'].astype(str) + '_' + test['month'].astype(str)\n",
    "    test['group_covid'] = group_covid(test)\n",
    "    test['group_season'] = group_season(test)\n",
    "    test['group_day'] = group_day(test)\n",
    "    test['group_time'] = group_time(test)\n",
    "    test['group_built'] = group_built(test)\n",
    "    test['log_DIST'] = log_DIST(test)\n",
    "    test['DIST_LENGTH'] = DIST_LENGTH(test)\n",
    "    \n",
    "    print('Test dataset success !')\n",
    "\n",
    "    str_col = ['year_month' , 'group_covid', 'group_season', 'group_day', 'group_time', 'group_built', 'ARI_INFO']\n",
    "    \n",
    "    for i in str_col:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(train[i])\n",
    "        train[i] = le.transform(train[i])\n",
    "\n",
    "        for label in np.unique(test[i]):\n",
    "            if label not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, label)\n",
    "        test[i] = le.transform(test[i])\n",
    "    \n",
    "    X = train.drop(    \n",
    "        ['SAMPLE_ID' ,'ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'date', 'FLAG', 'CI_HOUR'], axis=1\n",
    "    )\n",
    "\n",
    "    y = train['CI_HOUR']\n",
    "\n",
    "    test = test.drop(\n",
    "        ['SAMPLE_ID', 'ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'date', 'FLAG'], axis=1\n",
    "    )\n",
    "\n",
    "    End = datetime.now()\n",
    "    print(f'End time: {End}')\n",
    "    print('Play time: ', End - start)\n",
    "    \n",
    "    return X, y, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba012a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_test = make_dataset(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88550879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Cycling Transform \n",
    "##시간\n",
    "X['sin_hour'] = np.sin(2 * np.pi * X['hour']/23.0)\n",
    "X['cos_hour'] = np.cos(2 * np.pi * X['hour']/23.0)\n",
    "X_test['sin_hour'] = np.sin(2 * np.pi * X_test['hour']/23.0)\n",
    "X_test['cos_hour'] = np.cos(2 * np.pi * X_test['hour']/23.0)\n",
    "\n",
    "##분\n",
    "X['sin_minute'] = np.sin(2 * np.pi * X['minute']/59.0)\n",
    "X['cos_minute'] = np.cos(2 * np.pi * X['minute']/59.0)\n",
    "X_test['sin_minute'] = np.sin(2 * np.pi * X_test['minute']/59.0)\n",
    "X_test['cos_minute'] = np.cos(2 * np.pi * X_test['minute']/59.0)\n",
    "\n",
    "##날짜\n",
    "X['sin_date'] = -np.sin(2 * np.pi * (X['month']+X['day']/31)/12)\n",
    "X['cos_date'] = -np.sin(2 * np.pi * (X['month']+X['day']/31)/12)\n",
    "X_test['sin_date'] = -np.sin(2 * np.pi * (X_test['month']+X_test['day']/31)/12)\n",
    "X_test['cos_date'] = -np.sin(2 * np.pi * (X_test['month']+X_test['day']/31)/12)\n",
    "\n",
    "##월\n",
    "X['sin_month'] = -np.sin(2 * np.pi * X['month']/12.0)\n",
    "X['cos_month'] = -np.cos(2 * np.pi * X['month']/12.0)\n",
    "X_test['sin_month'] = -np.sin(2 * np.pi * X_test['month']/12.0)\n",
    "X_test['cos_month'] = -np.cos(2 * np.pi * X_test['month']/12.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f205cbf-fbd7-45c0-9e08-7c3ab18db988",
   "metadata": {},
   "source": [
    "## 4. Model : LGBM & XGBOOST\n",
    "- optuna 사용 시, 학습데이터에 대해 Overfitting이 발생할 가능성이 있어 직접 파라미터들을 변경해가며 튜닝을 진행하였습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "iterations = 50000\n",
    "patience = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffa54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 끄기\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "models_lgb = []\n",
    "models_xgb = []\n",
    "mae_scores = []\n",
    "n_split_list = [10]\n",
    "\n",
    "for split in n_split_list:\n",
    "    fold_idx = 1\n",
    "    cv = KFold(n_splits=split, shuffle=True, random_state=42)\n",
    "    for train_index, valid_index in cv.split(X):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        Y_train, Y_valid = y[train_index], y[valid_index]\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        model_lgb = LGBMRegressor(boosting_type='gbdt',\n",
    "                            objective='regression_l1', \n",
    "                            n_estimators=iterations,\n",
    "                            max_depth=12,\n",
    "                            learning_rate=0.07,\n",
    "                            colsample_bytree=0.9,\n",
    "                            subsample=1.0,\n",
    "                            min_child_weight=60,\n",
    "                            num_leaves=512,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42)   \n",
    "                             \n",
    "    \n",
    "        model_lgb.fit(X_train, Y_train, \n",
    "                  eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "                  early_stopping_rounds=patience, \n",
    "                  verbose=100)\n",
    "        \n",
    "        model_xgb = XGBRegressor(n_estimators = iterations, eta = 0.15, min_child_weight = 60, \n",
    "                       max_depth = 10, colsample_bytree = 0.8,\n",
    "                       subsample = 1.0, seed = 42,\n",
    "                       objective = 'reg:absoluteerror',\n",
    "                       eval_metric = 'mae',\n",
    "                       tree_method=\"gpu_hist\")\n",
    "    \n",
    "        model_xgb.fit(X_train, Y_train, \n",
    "                  eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "                  early_stopping_rounds=patience, verbose=100)\n",
    "        \n",
    "        pred_lgb = model_lgb.predict(X_valid)\n",
    "        pred_xgb = model_xgb.predict(X_valid)\n",
    "        pred = pred_lgb*0.8 + pred_xgb*0.2\n",
    "        score = mean_absolute_error(Y_valid,pred)\n",
    "        print(fold_idx,\"Fold Validation MAE score :\", score)\n",
    "        mae_scores.append(score)\n",
    "        models_lgb.append(model_lgb)\n",
    "        models_xgb.append(model_xgb)\n",
    "        fold_idx += 1\n",
    "        if is_holdout:\n",
    "            break \n",
    "print(\"Validation : MAE scores for each fold:\", mae_scores)\n",
    "print(\"Validation : MAE:\", np.mean(mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3dcd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGBM feature importance\n",
    "for i in range(10):\n",
    "    predictors = X.columns\n",
    "    tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': models_lgb[i].feature_importances_})\n",
    "    tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "    plt.figure(figsize = (7,4))\n",
    "    plt.title('Features importance',fontsize=7)\n",
    "    s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "    s.set_xticklabels(s.get_xticklabels(),rotation=90, size=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82842b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST feature importance\n",
    "for i in range(10):\n",
    "    predictors = X.columns\n",
    "    tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': models_xgb[i].feature_importances_})\n",
    "    tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "    plt.figure(figsize = (7,4))\n",
    "    plt.title('Features importance',fontsize=7)\n",
    "    s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "    s.set_xticklabels(s.get_xticklabels(),rotation=90, size=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98af3b9-4d1e-4f68-9b58-a46ecf821ea9",
   "metadata": {},
   "source": [
    "## 5. test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(10):\n",
    "    pred_lgb = models_lgb[i].predict(X_test)\n",
    "    pred_xgb = models_xgb[i].predict(X_test)\n",
    "    pred = pred_lgb*0.8 + pred_xgb*0.2\n",
    "    preds.append(pred)\n",
    "\n",
    "preds = np.mean(preds , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521eb6cf-f4bd-485f-8f30-3d442c22d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측값 할당\n",
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['CI_HOUR'] = preds\n",
    "\n",
    "#DIST가 0인 Target 값 후처리\n",
    "index_0 = test[test['DIST'] == 0].index\n",
    "submission.loc[index_0, 'CI_HOUR'] = 0.0\n",
    "\n",
    "#음수값 후처리\n",
    "submission.loc[submission['CI_HOUR'] < 0, 'CI_HOUR'] = 0.0\n",
    "\n",
    "submission.to_csv('./submissions/final_sub_woo.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68faf897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
